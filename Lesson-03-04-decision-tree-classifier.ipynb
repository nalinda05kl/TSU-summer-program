{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Introduction to machine learning (2 1/2 weeks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 3.4: Decision Tree Classifier \n",
    "* Contents of this notebook are taken from : http://dataaspirant.com/2017/02/01/decision-tree-algorithm-python-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Introduction <br>\n",
    "Decision Tree Algorithm is one of the widely used and effciecnt supervised algorithms. It can be used for both the classification as well as regression purposes. The algorithm works directing towards searching the roots of the data set form all available attributes. At the begining, all attributes are consider as roots and eventually end up having the best roots after the training process is compleated. In the training, this is done by checking the composition of sub sets in each division. If the resulted subset can not be divided further, then it is considered to be end of the decesion making and called a leaf. Decision making criterian are based on two aproaches: gini index OR information gain. More details on popular attribute selection measures please visit:\n",
    "1. Gini Index: https://en.wikipedia.org/wiki/Gini_coefficient <br>\n",
    "2. Information Gain: https://en.wikipedia.org/wiki/Information_gain_in_decision_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DT.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Classification in to two classes <br>\n",
    "In the following example, a simulated data set is used to see the working procedure and special features of the decision tree classifier using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nalindakulathunga/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_data = pd.read_csv(\n",
    "'https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data', sep= ',', header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  B  1  1  1  1\n",
       "1  R  1  1  1  2\n",
       "2  R  1  1  1  3\n",
       "3  R  1  1  1  4\n",
       "4  R  1  1  1  5\n",
       "5  R  1  1  2  1\n",
       "6  R  1  1  2  2\n",
       "7  R  1  1  2  3\n",
       "8  R  1  1  2  4\n",
       "9  R  1  1  2  5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Please consider, the 0th attribute is for the label and other four attributes are for features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Lenght::  625\n",
      "Dataset Shape::  (625, 5)\n"
     ]
    }
   ],
   "source": [
    "print \"Dataset Lenght:: \", len(balance_data)\n",
    "print \"Dataset Shape:: \", balance_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = balance_data.values[:, 1:5]\n",
    "Y = balance_data.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=4,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=100, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100, max_depth=7, min_samples_leaf=4)\n",
    "clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=7,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=4,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=100, splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100,\n",
    " max_depth=7, min_samples_leaf=4)\n",
    "clf_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gini.predict([[1, 1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['L', 'L', 'R', 'L', 'R', 'L', 'R', 'L', 'L', 'L', 'L', 'L', 'R',\n",
       "       'L', 'R', 'R', 'L', 'L', 'R', 'L', 'R', 'L', 'B', 'L', 'R', 'L',\n",
       "       'L', 'L', 'R', 'L', 'L', 'L', 'R', 'L', 'L', 'L', 'R', 'R', 'L',\n",
       "       'L', 'R', 'L', 'R', 'L', 'R', 'R', 'L', 'B', 'R', 'L', 'B', 'R',\n",
       "       'L', 'B', 'R', 'L', 'R', 'R', 'L', 'B', 'B', 'R', 'L', 'L', 'L',\n",
       "       'R', 'R', 'R', 'R', 'L', 'L', 'R', 'R', 'L', 'R', 'L', 'R', 'R',\n",
       "       'R', 'L', 'R', 'R', 'L', 'R', 'L', 'R', 'R', 'L', 'R', 'L', 'R',\n",
       "       'R', 'L', 'L', 'L', 'R', 'R', 'L', 'L', 'L', 'R', 'L', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'B', 'L', 'R', 'L', 'R', 'R', 'L', 'L', 'R',\n",
       "       'R', 'R', 'R', 'L', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'R',\n",
       "       'R', 'R', 'R', 'L', 'R', 'R', 'R', 'L', 'L', 'R', 'L', 'B', 'L',\n",
       "       'R', 'L', 'L', 'R', 'L', 'R', 'R', 'L', 'L', 'L', 'R', 'R', 'R',\n",
       "       'L', 'R', 'R', 'B', 'R', 'R', 'B', 'L', 'R', 'R', 'L', 'R', 'R',\n",
       "       'R', 'B', 'R', 'B', 'R', 'R', 'R', 'R', 'L', 'R', 'R', 'B', 'R',\n",
       "       'R', 'L', 'L', 'R', 'R', 'R'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_gini = clf_gini.predict(X_test)\n",
    "y_pred_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  79.7872340425532\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy is :\", accuracy_score(y_test,y_pred_gini)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['L', 'L', 'R', 'L', 'R', 'L', 'R', 'L', 'L', 'R', 'R', 'L', 'R',\n",
       "       'L', 'R', 'R', 'L', 'L', 'R', 'L', 'R', 'R', 'B', 'L', 'R', 'L',\n",
       "       'L', 'L', 'R', 'L', 'R', 'L', 'L', 'L', 'B', 'L', 'R', 'B', 'B',\n",
       "       'L', 'L', 'L', 'R', 'L', 'R', 'R', 'L', 'B', 'R', 'L', 'L', 'R',\n",
       "       'L', 'L', 'R', 'L', 'R', 'R', 'L', 'B', 'B', 'R', 'L', 'L', 'R',\n",
       "       'R', 'R', 'R', 'B', 'L', 'L', 'L', 'R', 'L', 'R', 'L', 'L', 'R',\n",
       "       'R', 'L', 'R', 'R', 'L', 'R', 'L', 'L', 'R', 'L', 'R', 'L', 'R',\n",
       "       'R', 'L', 'L', 'L', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'B', 'R',\n",
       "       'L', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'R', 'R', 'L', 'B', 'R',\n",
       "       'R', 'R', 'R', 'L', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'R',\n",
       "       'R', 'R', 'R', 'L', 'R', 'R', 'R', 'L', 'L', 'R', 'L', 'R', 'L',\n",
       "       'R', 'L', 'L', 'R', 'L', 'R', 'R', 'L', 'L', 'L', 'R', 'R', 'R',\n",
       "       'L', 'R', 'R', 'B', 'R', 'L', 'B', 'L', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'L', 'L', 'B', 'R', 'R', 'R', 'R', 'L', 'R', 'R', 'B', 'R',\n",
       "       'R', 'L', 'L', 'L', 'R', 'R'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_entropy = clf_entropy.predict(X_test)\n",
    "y_pred_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  78.19148936170212\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy is :\", accuracy_score(y_test,y_pred_entropy)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Exercise 3.4</font> <br>\n",
    "\n",
    "* Repeat the above classifing procedure for different tree depths: \"max_depth\" (2-10) and different minimum number of leaves required: \"min_samples_leaf\" (7-2) and list the resulting accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
